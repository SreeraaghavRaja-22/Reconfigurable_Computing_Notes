## Other Economic Considerations
- Time to market
	- Huge effect on total revenue  ![[Pasted image 20250922012216.png]]
	- FPGAs have a much faster time to market than an ASIC, but both are much slower than software 
	- Delayed time to market = less revenue

---
## Miscellaneous Considerations 
- Will application have to change or adapt after deployment? 
	- Can't change ASIC (actual hardware)
		- EFPGA is a way to make the ASIC a little more reconfigurable
	- Can change circuit implemented in FPGA (virtual hardware)
- USES
	- When standards change 
	- Allows new features to existing devices
	- Allows bug and security fixes 
	- Fault tolerance/recovery 
	- **"Partial reconfiguration"** allows virtual device with arbitrary size - analogous to virtual memory 
		- Can configure portions of your FPGA

- Without FPGA 
	- Anything that may have to be reconfigured is implemented in software 
		- Performance loss
---
## Optimization Goals and Constraints 
- Goals and constraints have a huge impact on device choice
- High Performance Computing 
	- Super computing 
	- Common Optimization Goal of maximizing performance with power and cost constraints 
	- GPU attractive if power constraints are met 
	- FPGA attractive if GPU consumes too much power, if goal is to minimize energy costs 
- Embedded Systems 
	- Common goal: minimize power given a performance constraint 
	- High-end GPU might violate power constraints, low-power GPU might be slower than an FPGA 
	- FPGA often attractive because of low energy and power
- Data Center 
	- Common goal: meet throughput constraints while minimizing energy and cooling costs 
	- FPGA attractive even if GPU is faster due to lower power, energy, and cooling costs
		- Examples: Microsoft Catapult and Amazon EC2 F1
			- In nearly every Microsoft Data Center

---
## Application Characteristics
- Many characteristics and affect best choice of device 
- Common characteristics: 
	- Parallelism (types and amounts) and dependencies 
	- Arithmetic Type (floating point, fixed point, integer, bitwise logic)
	- Branching 
	- Memory Requirements 
	- Sensitivity to memory and I/O Bandwidth 
	- Data structures and memory access patterns 
- No known equation to automatically determine best device 
- Understanding these characteristics in first step in exploration
---
## Architecture Characteristics 
- Device architecture considerations 
	- **Peak computation throughput** -- have an understanding of what this value is 
	- GPU: number of cores, clock frequency, on-chip memory, etc. 
	- FPGA: # of look-up tables (LUTs), DSPs, embedded RAM, clock frequency, etc. 
- Board architecture often just as important 
- Different Boards have different tradeoffs
	- PCIe accelerators
		- high peak computational throughput 
		- but, data must be transferred from CPU into board/device memory 
		- different boards with same accelerator may provide different memory sizes and bandwidths
	- System-on-Chip (SoC)
		- Eliminates PCIe overhead, external memory bandwidth overhead
		- But, limited peak computation throughput
	- Custom Boards 
		- FPGA on a network-interface card (Microsoft Catapult) for ultra-low latency network processing
---
## Input Size and Characteristics 
- Input can have a significant effect on performance and/or energy 
	- Small inputs might not use all GPU cores or amortize PCIe overheads
	- Large inputs might not fit in on-board memory on one accelerator 
- Example: Convolution Study
	- Different Devices: 
		- GPU, FPGA, multi-core GPU ![[Pasted image 20250922015249.png]]
	- Different algorithms: 
		- Time-Domain convolution (Time)
		- Frequency domain convolution (FFT)
	- Some applications have a data-dependent performance 
		- different amounts of thread divergence in GPU

--- 
## Common GPU/FPGA Trends
- GPUs *usually* provide fastest performance when application: 
	- has large amounts of SIMT floating-point parallelism (loops with fine-grained, independent iterations)
	- Control flow does not diverge(i.e all threads follow the same path through a function)
- FPGAs *can* provide fastest performance when: 
	- GPU can't realize peak performance due to SIMT bottlenecks
		- Divergence, stalls, communication, overhead, insufficient SIMT parallelism
	- Custom fixed-point precision or bit operations 
- FPGAs *usually* consume less power than GPU
	- 10s of Watts vs. 100+ Watts
		- FPGAs are a little higher now but nowhere near GPU levels
- FPGAs *can* use less energy 
	- Depends on performance difference
- GPUs *usually* much easier to program compared to FPGA
	- Intel OneAPI and DPC++ trying to hide many of the programming differences 
---
## How to choose a device?

#### Bare Minimum Approach
- Determine architectures that meet all constraints
	- Not trivial, requires performance analysis/estimation - important problem 
		- Will study later in semester 
- Estimate volume of application 
	- Requires understanding of market 
- Determine the cheapest approach
- The best device for an application is typically the cheapest one that meets all design constraints 

#### More Complicated Approach 
- Determine devices that meet all constraints 
- Analyze Pareto-Optimal tradeoffs of those devices 
	- Includes cost and optimization goals 
- Choose solution that is most attractive for application and use case

--- 
## Where are FPGAs used?
- ASIC prototyping (first main market for FPGAs)
	- Validate ASIC on many FPGAs before fabricating 
- ASIC replacement 
	- If ASIC prototyped in FPGA, and FPGA has attractive tradeoffs, just deploy FPGA
- IoT, embedded systems, cyber-physical systems
	- e.g. networking, signal-processing, automotive 
	- Advantages
		- FPGAs achieve performance close to ASIC, sometimes at much lower cost (ASIC replacement)
			- High volume systems still use ASICs (phones)
				- but ASICs are less common now because they are expensive 
		- Reconfigurable 
			- if standards change, the architecture can be fixed
				- Can add new features (or fix issues) after production
- Domains require low-latency acceleration 
	- Usually on SmartNICs (FPGA on network card)
		- high-frequency trading, web searches, and real-time systems
		- Microsoft used FPGAs to accelerate Bing Searches 
- Data centers and cloud computing (a while ago)
	- Servers were combined with FPGAs
	- Microsoft Catapult 
		- used to accelerate Bing searches 
		- used for a variety of machine-learning applications 
	- Amazon F1
		- FPGAs integrates into EC2 compute cloud 
	- Baidu
		- uses FPGAs for machine learning 
- Advantages
	- low power, ASIC rarely feasible, microprocessor too slow
- High-performance embedded computing (HPEC)
	- High-performance/super computing with special needs (low power, low size/weight, etc)
		- Satellite image processing 
		- Defense applications
	- FPGA advantages 
		- much smaller and lower power than a supercomputer 
		- provide fault tolerance mechanisms
- Energy Efficient high-performance computing (HPC)
	- Mid 2000s: first appearance of high-end processors with FPGA accelerator boards 
	- only exists where energy is super important 
- FPGA Advantages
	- HPC used for many scientific apps
	- Low power consumption 
		- very important + cooling and energy costs are a dominant factor in total cost of ownership

---
## Where are FPGAs Not Used? 
- General Purpose Computing 
	- Problems: 
		- FPGAs can be very fast, but not for everything 
			- requires parallel algorithms 
	- Common coding constructs are not appropriate for hardware 
	- Subject of tremendous amount of past and ongoing research 
- High-volume applications 
	- Cell phones 
	- Machine Learning (FPGAs are a competitor, but ASICs are becoming more common)
	- Googles' Tensor Processing Unit (TPU)
	- FGPAs vs GPU competition has no clear winner yet 
		- GPUS are faster but take more power 
		- FPGAs are slower and harder to program but less power and can get new models 
	- Gaming, 3D Graphics 
		- NVIDIA's GPUs are specialized ASICs
---
## Limitations of FPGAs
- Peak throughput is far below high-end GPUs
	- For any application that maps well onto GPU, FPGA will be much slower 
- Programming FPGAs considerably more difficult than software
	- FPGA productivity at least 10x worse than software
	- Generally requires low-level digital-design expertise to perform well 
- Device costs can be prohibitive 
	- Largest FPGAs cost $10k
	- Making FPGAs more usable would be lower unit costs via economy of scale